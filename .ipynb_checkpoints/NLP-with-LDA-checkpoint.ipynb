{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Badges.csv', 'CloseAsOffTopicReasonTypes.csv', 'CloseReasonTypes.csv', 'Comments.csv', 'FlagTypes.csv', 'PendingFlags.csv', 'PostFeedback.csv', 'PostHistory.csv', 'PostHistoryTypes.csv', 'PostLinks.csv', 'PostNotices.csv', 'PostNoticeTypes.csv', 'PostsWithDeleted.csv', 'Posts_a.csv', 'Posts_b.csv', 'Posts_c.csv', 'PostTags.csv', 'PostTypes.csv', 'queries001.txt', 'ReviewRejectionReasons.csv', 'ReviewTaskResults.csv', 'ReviewTaskResultTypes.csv', 'ReviewTasks.csv', 'ReviewTaskStates.csv', 'ReviewTaskTypes.csv', 'SuggestedEdits.csv', 'SuggestedEditVotes.csv', 'Tags.csv', 'TagSynonyms.csv', 'Users_a.csv', 'Users_b.csv', 'Votes.csv', 'VoteTypes.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johannes\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.random.seed(2018)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from os import listdir\n",
    "print(listdir(\"stackexchange/input\"))\n",
    "\n",
    "# read csv (comma separated value) into data\n",
    "data = pd.read_csv('stackexchange/input/Posts_a.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34291 entries, 0 to 34290\n",
      "Data columns (total 22 columns):\n",
      "Id                       34291 non-null int64\n",
      "PostTypeId               34291 non-null int64\n",
      "AcceptedAnswerId         4925 non-null float64\n",
      "ParentId                 25503 non-null float64\n",
      "CreationDate             34291 non-null object\n",
      "DeletionDate             0 non-null float64\n",
      "Score                    34291 non-null int64\n",
      "ViewCount                7837 non-null float64\n",
      "Body                     34125 non-null object\n",
      "OwnerUserId              33348 non-null float64\n",
      "OwnerDisplayName         1824 non-null object\n",
      "LastEditorUserId         13006 non-null float64\n",
      "LastEditorDisplayName    38 non-null object\n",
      "LastEditDate             13037 non-null object\n",
      "LastActivityDate         34291 non-null object\n",
      "Title                    7837 non-null object\n",
      "Tags                     7837 non-null object\n",
      "AnswerCount              7837 non-null float64\n",
      "CommentCount             34291 non-null int64\n",
      "FavoriteCount            4229 non-null float64\n",
      "ClosedDate               973 non-null object\n",
      "CommunityOwnedDate       583 non-null object\n",
      "dtypes: float64(8), int64(4), object(10)\n",
      "memory usage: 5.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data.info()\n",
    "type(data['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK: Topic modeling with LDA\n",
    "Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.\n",
    "\n",
    "## Source:\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are radial contextual menus better than vertic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is an acceptable response time for my aja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the important aspect to consider when ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What can be done to make a long, multi-step wi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What screen vertical resolution should I cater...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  index\n",
       "0  Are radial contextual menus better than vertic...      0\n",
       "1  What is an acceptable response time for my aja...      1\n",
       "5  What is the important aspect to consider when ...      5\n",
       "7  What can be done to make a long, multi-step wi...      7\n",
       "9  What screen vertical resolution should I cater...      9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only the titles of the questions of the datasets \n",
    "data_title = data[[\"Title\"]]\n",
    "data_title = data_title.dropna() \n",
    "data_title['index'] = data_title.index\n",
    "documents = data_title\n",
    "documents.head()\n",
    "#type(documents['Title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "\n",
    "Words that have fewer than 3 characters are removed.\n",
    "\n",
    "All stopwords are removed.\n",
    "\n",
    "Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "\n",
    "Words are stemmed — words are reduced to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Johannes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [radial, contextu, menus, better, vertic, list...\n",
       "1                        [accept, respons, time, ajax]\n",
       "5    [import, aspect, consid, decid, window, intera...\n",
       "7            [long, multi, step, wizard, user, friend]\n",
       "9     [screen, vertic, resolut, cater, phone, browser]\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lematize and stem functions\n",
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "#preprocess\n",
    "processed_docs = documents[\"Title\"].map(preprocess)\n",
    "processed_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 2), (3, 1)],\n",
       " [(4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(3, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set.\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Gensim filter_extremes\n",
    "# Filter out tokens that appear in less than 15 documents (absolute number) or\n",
    "# more than 0.5 documents (fraction of total corpus size, not absolute number). (TODO: why?)\n",
    "# after the above two steps, keep only the first 100000 most frequent tokens.\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "#For each document we create a dictionary reporting how many words and how many times those words appear.\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word #0 radial appears 1 times\n",
      "Word #1 contextu appears 1 times\n",
      "Word #2 menus appears 2 times\n",
      "Word #3 better appears 1 times\n"
     ]
    }
   ],
   "source": [
    "# Preview Bag Of Words \n",
    "bow_doc_sample = bow_corpus[0]\n",
    "for i in range(len(bow_doc_sample)):\n",
    "    print(\"Word #{} {} appears {} times\".format(bow_doc_sample[i][0],\n",
    "                                                processed_docs[0][i],\n",
    "                                                bow_doc_sample[i][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.31955709005753125),\n",
      " (1, 0.2727205093107365),\n",
      " (2, 0.8109853879304021),\n",
      " (3, 0.407197115115801)]\n"
     ]
    }
   ],
   "source": [
    "# Create tf-idf model \n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# apply transformation to the entire corpus \n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "# preview TF-IDF scores for our first document\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [radial, contextu, menus, better, vertic, list...\n",
       "1                        [accept, respons, time, ajax]\n",
       "5    [import, aspect, consid, decid, window, intera...\n",
       "7            [long, multi, step, wizard, user, friend]\n",
       "9     [screen, vertic, resolut, cater, phone, browser]\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 accept\n",
      "5 ajax\n",
      "6 respons\n",
      "7 time\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,8):\n",
    "    print(i,dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 2), (3, 1)],\n",
       " [(4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(3, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our lda model\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.038*\"data\" + 0.035*\"display\" + 0.035*\"user\" + 0.035*\"best\" + 0.017*\"list\" + 0.017*\"interfac\" + 0.016*\"practic\" + 0.014*\"idea\" + 0.014*\"icon\" + 0.013*\"good\"\n",
      "Topic: 1 \n",
      "Words: 0.064*\"page\" + 0.056*\"best\" + 0.030*\"form\" + 0.027*\"button\" + 0.025*\"differ\" + 0.022*\"websit\" + 0.019*\"site\" + 0.017*\"right\" + 0.016*\"practic\" + 0.015*\"link\"\n",
      "Topic: 2 \n",
      "Words: 0.047*\"select\" + 0.025*\"filter\" + 0.024*\"time\" + 0.021*\"button\" + 0.019*\"dialog\" + 0.016*\"control\" + 0.015*\"chang\" + 0.013*\"style\" + 0.012*\"user\" + 0.012*\"progress\"\n",
      "Topic: 3 \n",
      "Words: 0.059*\"user\" + 0.025*\"window\" + 0.019*\"form\" + 0.018*\"button\" + 0.018*\"applic\" + 0.017*\"design\" + 0.017*\"grid\" + 0.015*\"test\" + 0.013*\"order\" + 0.011*\"better\"\n",
      "Topic: 4 \n",
      "Words: 0.046*\"button\" + 0.033*\"user\" + 0.023*\"screen\" + 0.020*\"navig\" + 0.019*\"applic\" + 0.018*\"menu\" + 0.016*\"indic\" + 0.015*\"color\" + 0.013*\"mobil\" + 0.013*\"tab\"\n",
      "Topic: 5 \n",
      "Words: 0.038*\"search\" + 0.035*\"mobil\" + 0.030*\"button\" + 0.030*\"tabl\" + 0.023*\"text\" + 0.018*\"action\" + 0.016*\"user\" + 0.016*\"click\" + 0.013*\"devic\" + 0.013*\"navig\"\n",
      "Topic: 6 \n",
      "Words: 0.075*\"user\" + 0.025*\"field\" + 0.019*\"icon\" + 0.018*\"content\" + 0.014*\"menu\" + 0.013*\"list\" + 0.013*\"manag\" + 0.013*\"item\" + 0.013*\"label\" + 0.012*\"navig\"\n",
      "Topic: 7 \n",
      "Words: 0.036*\"best\" + 0.034*\"multipl\" + 0.024*\"user\" + 0.019*\"websit\" + 0.019*\"result\" + 0.016*\"link\" + 0.016*\"page\" + 0.015*\"interfac\" + 0.014*\"item\" + 0.014*\"password\"\n",
      "Topic: 8 \n",
      "Words: 0.096*\"design\" + 0.078*\"user\" + 0.028*\"usabl\" + 0.027*\"good\" + 0.021*\"mobil\" + 0.020*\"pattern\" + 0.018*\"test\" + 0.012*\"inform\" + 0.012*\"experi\" + 0.012*\"best\"\n",
      "Topic: 9 \n",
      "Words: 0.035*\"field\" + 0.033*\"list\" + 0.032*\"form\" + 0.026*\"messag\" + 0.025*\"user\" + 0.018*\"improv\" + 0.017*\"input\" + 0.016*\"button\" + 0.015*\"long\" + 0.014*\"error\"\n"
     ]
    }
   ],
   "source": [
    "# For each topic, we will explore the words occuring in that topic and its relative weight.\n",
    "# Goal is to detect topics based on the words in each group  \n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.048*\"user\" + 0.030*\"experi\" + 0.020*\"design\" + 0.013*\"valu\" + 0.012*\"websit\" + 0.011*\"menu\" + 0.011*\"posit\" + 0.011*\"click\" + 0.010*\"devic\" + 0.010*\"button\"\n",
      "Topic: 1 Word: 0.038*\"design\" + 0.027*\"good\" + 0.012*\"navig\" + 0.012*\"mobil\" + 0.012*\"user\" + 0.012*\"form\" + 0.011*\"idea\" + 0.011*\"desktop\" + 0.011*\"input\" + 0.010*\"dropdown\"\n",
      "Topic: 2 Word: 0.037*\"best\" + 0.030*\"practic\" + 0.024*\"page\" + 0.020*\"user\" + 0.015*\"indic\" + 0.014*\"select\" + 0.013*\"usabl\" + 0.012*\"form\" + 0.012*\"design\" + 0.012*\"pattern\"\n",
      "Topic: 3 Word: 0.020*\"search\" + 0.017*\"user\" + 0.017*\"display\" + 0.017*\"list\" + 0.017*\"button\" + 0.016*\"data\" + 0.013*\"option\" + 0.012*\"tabl\" + 0.011*\"best\" + 0.011*\"research\"\n",
      "Topic: 4 Word: 0.029*\"interfac\" + 0.019*\"user\" + 0.017*\"form\" + 0.012*\"prototyp\" + 0.012*\"word\" + 0.012*\"touch\" + 0.012*\"tab\" + 0.011*\"tool\" + 0.011*\"multipl\" + 0.011*\"vertic\"\n",
      "Topic: 5 Word: 0.016*\"view\" + 0.015*\"right\" + 0.014*\"mobil\" + 0.012*\"navig\" + 0.012*\"site\" + 0.011*\"date\" + 0.011*\"filter\" + 0.010*\"best\" + 0.010*\"select\" + 0.010*\"user\"\n",
      "Topic: 6 Word: 0.030*\"button\" + 0.025*\"icon\" + 0.017*\"item\" + 0.015*\"text\" + 0.014*\"best\" + 0.014*\"websit\" + 0.013*\"languag\" + 0.013*\"user\" + 0.013*\"list\" + 0.010*\"usabl\"\n",
      "Topic: 7 Word: 0.022*\"button\" + 0.020*\"list\" + 0.018*\"display\" + 0.014*\"search\" + 0.014*\"time\" + 0.013*\"usabl\" + 0.012*\"content\" + 0.012*\"page\" + 0.012*\"data\" + 0.012*\"modal\"\n",
      "Topic: 8 Word: 0.023*\"user\" + 0.017*\"applic\" + 0.015*\"android\" + 0.014*\"test\" + 0.014*\"interfac\" + 0.014*\"best\" + 0.012*\"page\" + 0.012*\"process\" + 0.012*\"recommend\" + 0.011*\"form\"\n",
      "Topic: 9 Word: 0.023*\"differ\" + 0.020*\"page\" + 0.016*\"design\" + 0.015*\"navig\" + 0.015*\"like\" + 0.014*\"work\" + 0.014*\"mobil\" + 0.014*\"app\" + 0.013*\"websit\" + 0.012*\"look\"\n"
     ]
    }
   ],
   "source": [
    "# Running LDA using TF-IDF\n",
    "# Again to distinguish different topics using the words in each topic and their corresponding weights\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radial', 'contextu', 'menus', 'better', 'vertic', 'list', 'menus']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance evaluation by classifying sample document using LDA Bag of Words model\n",
    "# We will check where our test document would be classified.\n",
    "processed_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5636433959007263\t \n",
      "Topic: 0.046*\"button\" + 0.033*\"user\" + 0.023*\"screen\" + 0.020*\"navig\" + 0.019*\"applic\" + 0.018*\"menu\" + 0.016*\"indic\" + 0.015*\"color\" + 0.013*\"mobil\" + 0.013*\"tab\"\n",
      "\n",
      "Score: 0.3029978275299072\t \n",
      "Topic: 0.075*\"user\" + 0.025*\"field\" + 0.019*\"icon\" + 0.018*\"content\" + 0.014*\"menu\" + 0.013*\"list\" + 0.013*\"manag\" + 0.013*\"item\" + 0.013*\"label\" + 0.012*\"navig\"\n",
      "\n",
      "Score: 0.01667226292192936\t \n",
      "Topic: 0.035*\"field\" + 0.033*\"list\" + 0.032*\"form\" + 0.026*\"messag\" + 0.025*\"user\" + 0.018*\"improv\" + 0.017*\"input\" + 0.016*\"button\" + 0.015*\"long\" + 0.014*\"error\"\n",
      "\n",
      "Score: 0.016671394929289818\t \n",
      "Topic: 0.059*\"user\" + 0.025*\"window\" + 0.019*\"form\" + 0.018*\"button\" + 0.018*\"applic\" + 0.017*\"design\" + 0.017*\"grid\" + 0.015*\"test\" + 0.013*\"order\" + 0.011*\"better\"\n",
      "\n",
      "Score: 0.01667131297290325\t \n",
      "Topic: 0.038*\"search\" + 0.035*\"mobil\" + 0.030*\"button\" + 0.030*\"tabl\" + 0.023*\"text\" + 0.018*\"action\" + 0.016*\"user\" + 0.016*\"click\" + 0.013*\"devic\" + 0.013*\"navig\"\n",
      "\n",
      "Score: 0.016669973731040955\t \n",
      "Topic: 0.047*\"select\" + 0.025*\"filter\" + 0.024*\"time\" + 0.021*\"button\" + 0.019*\"dialog\" + 0.016*\"control\" + 0.015*\"chang\" + 0.013*\"style\" + 0.012*\"user\" + 0.012*\"progress\"\n",
      "\n",
      "Score: 0.016669871285557747\t \n",
      "Topic: 0.038*\"data\" + 0.035*\"display\" + 0.035*\"user\" + 0.035*\"best\" + 0.017*\"list\" + 0.017*\"interfac\" + 0.016*\"practic\" + 0.014*\"idea\" + 0.014*\"icon\" + 0.013*\"good\"\n",
      "\n",
      "Score: 0.016668574884533882\t \n",
      "Topic: 0.036*\"best\" + 0.034*\"multipl\" + 0.024*\"user\" + 0.019*\"websit\" + 0.019*\"result\" + 0.016*\"link\" + 0.016*\"page\" + 0.015*\"interfac\" + 0.014*\"item\" + 0.014*\"password\"\n",
      "\n",
      "Score: 0.01666802354156971\t \n",
      "Topic: 0.064*\"page\" + 0.056*\"best\" + 0.030*\"form\" + 0.027*\"button\" + 0.025*\"differ\" + 0.022*\"websit\" + 0.019*\"site\" + 0.017*\"right\" + 0.016*\"practic\" + 0.015*\"link\"\n",
      "\n",
      "Score: 0.016667360439896584\t \n",
      "Topic: 0.096*\"design\" + 0.078*\"user\" + 0.028*\"usabl\" + 0.027*\"good\" + 0.021*\"mobil\" + 0.020*\"pattern\" + 0.018*\"test\" + 0.012*\"inform\" + 0.012*\"experi\" + 0.012*\"best\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[0]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8499661087989807\t \n",
      "Topic: 0.029*\"interfac\" + 0.019*\"user\" + 0.017*\"form\" + 0.012*\"prototyp\" + 0.012*\"word\" + 0.012*\"touch\" + 0.012*\"tab\" + 0.011*\"tool\" + 0.011*\"multipl\" + 0.011*\"vertic\"\n",
      "\n",
      "Score: 0.01667286641895771\t \n",
      "Topic: 0.030*\"button\" + 0.025*\"icon\" + 0.017*\"item\" + 0.015*\"text\" + 0.014*\"best\" + 0.014*\"websit\" + 0.013*\"languag\" + 0.013*\"user\" + 0.013*\"list\" + 0.010*\"usabl\"\n",
      "\n",
      "Score: 0.016672568395733833\t \n",
      "Topic: 0.022*\"button\" + 0.020*\"list\" + 0.018*\"display\" + 0.014*\"search\" + 0.014*\"time\" + 0.013*\"usabl\" + 0.012*\"content\" + 0.012*\"page\" + 0.012*\"data\" + 0.012*\"modal\"\n",
      "\n",
      "Score: 0.016671955585479736\t \n",
      "Topic: 0.020*\"search\" + 0.017*\"user\" + 0.017*\"display\" + 0.017*\"list\" + 0.017*\"button\" + 0.016*\"data\" + 0.013*\"option\" + 0.012*\"tabl\" + 0.011*\"best\" + 0.011*\"research\"\n",
      "\n",
      "Score: 0.016670648008584976\t \n",
      "Topic: 0.023*\"user\" + 0.017*\"applic\" + 0.015*\"android\" + 0.014*\"test\" + 0.014*\"interfac\" + 0.014*\"best\" + 0.012*\"page\" + 0.012*\"process\" + 0.012*\"recommend\" + 0.011*\"form\"\n",
      "\n",
      "Score: 0.01666986383497715\t \n",
      "Topic: 0.023*\"differ\" + 0.020*\"page\" + 0.016*\"design\" + 0.015*\"navig\" + 0.015*\"like\" + 0.014*\"work\" + 0.014*\"mobil\" + 0.014*\"app\" + 0.013*\"websit\" + 0.012*\"look\"\n",
      "\n",
      "Score: 0.016669806092977524\t \n",
      "Topic: 0.038*\"design\" + 0.027*\"good\" + 0.012*\"navig\" + 0.012*\"mobil\" + 0.012*\"user\" + 0.012*\"form\" + 0.011*\"idea\" + 0.011*\"desktop\" + 0.011*\"input\" + 0.010*\"dropdown\"\n",
      "\n",
      "Score: 0.016669267788529396\t \n",
      "Topic: 0.016*\"view\" + 0.015*\"right\" + 0.014*\"mobil\" + 0.012*\"navig\" + 0.012*\"site\" + 0.011*\"date\" + 0.011*\"filter\" + 0.010*\"best\" + 0.010*\"select\" + 0.010*\"user\"\n",
      "\n",
      "Score: 0.01666879467666149\t \n",
      "Topic: 0.048*\"user\" + 0.030*\"experi\" + 0.020*\"design\" + 0.013*\"valu\" + 0.012*\"websit\" + 0.011*\"menu\" + 0.011*\"posit\" + 0.011*\"click\" + 0.010*\"devic\" + 0.010*\"button\"\n",
      "\n",
      "Score: 0.01666812039911747\t \n",
      "Topic: 0.037*\"best\" + 0.030*\"practic\" + 0.024*\"page\" + 0.020*\"user\" + 0.015*\"indic\" + 0.014*\"select\" + 0.013*\"usabl\" + 0.012*\"form\" + 0.012*\"design\" + 0.012*\"pattern\"\n"
     ]
    }
   ],
   "source": [
    "# Performance evaluation by classifying sample document using LDA TF-IDF model.\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[0]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6299756765365601\t Topic: 0.046*\"button\" + 0.033*\"user\" + 0.023*\"screen\" + 0.020*\"navig\" + 0.019*\"applic\"\n",
      "Score: 0.23666976392269135\t Topic: 0.036*\"best\" + 0.034*\"multipl\" + 0.024*\"user\" + 0.019*\"websit\" + 0.019*\"result\"\n",
      "Score: 0.016674991697072983\t Topic: 0.064*\"page\" + 0.056*\"best\" + 0.030*\"form\" + 0.027*\"button\" + 0.025*\"differ\"\n",
      "Score: 0.016670355573296547\t Topic: 0.038*\"search\" + 0.035*\"mobil\" + 0.030*\"button\" + 0.030*\"tabl\" + 0.023*\"text\"\n",
      "Score: 0.016668813303112984\t Topic: 0.059*\"user\" + 0.025*\"window\" + 0.019*\"form\" + 0.018*\"button\" + 0.018*\"applic\"\n",
      "Score: 0.016668668016791344\t Topic: 0.096*\"design\" + 0.078*\"user\" + 0.028*\"usabl\" + 0.027*\"good\" + 0.021*\"mobil\"\n",
      "Score: 0.016668183729052544\t Topic: 0.038*\"data\" + 0.035*\"display\" + 0.035*\"user\" + 0.035*\"best\" + 0.017*\"list\"\n",
      "Score: 0.016667930409312248\t Topic: 0.047*\"select\" + 0.025*\"filter\" + 0.024*\"time\" + 0.021*\"button\" + 0.019*\"dialog\"\n",
      "Score: 0.016667908057570457\t Topic: 0.075*\"user\" + 0.025*\"field\" + 0.019*\"icon\" + 0.018*\"content\" + 0.014*\"menu\"\n",
      "Score: 0.016667677089571953\t Topic: 0.035*\"field\" + 0.033*\"list\" + 0.032*\"form\" + 0.026*\"messag\" + 0.025*\"user\"\n"
     ]
    }
   ],
   "source": [
    "# testing model on unseen data\n",
    "unseen_document = 'How to modify an image to make it clear it\\'s an image (and not a clickable button.)'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
